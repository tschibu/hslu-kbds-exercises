{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-22 20:44:31,330 : INFO : collecting all words and their counts\n",
      "2019-10-22 20:44:31,819 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-10-22 20:44:31,974 : INFO : PROGRESS: at sentence #10000, processed 133456 words, keeping 9186 word types\n",
      "2019-10-22 20:44:32,125 : INFO : PROGRESS: at sentence #20000, processed 265279 words, keeping 11983 word types\n",
      "2019-10-22 20:44:32,917 : INFO : PROGRESS: at sentence #30000, processed 398618 words, keeping 14031 word types\n",
      "2019-10-22 20:44:33,071 : INFO : PROGRESS: at sentence #40000, processed 528012 words, keeping 15432 word types\n",
      "2019-10-22 20:44:33,215 : INFO : PROGRESS: at sentence #50000, processed 650964 words, keeping 16557 word types\n",
      "2019-10-22 20:44:33,968 : INFO : PROGRESS: at sentence #60000, processed 785700 words, keeping 17777 word types\n",
      "2019-10-22 20:44:34,125 : INFO : PROGRESS: at sentence #70000, processed 924133 words, keeping 18883 word types\n",
      "2019-10-22 20:44:34,279 : INFO : PROGRESS: at sentence #80000, processed 1058958 words, keeping 19752 word types\n",
      "2019-10-22 20:44:34,906 : INFO : PROGRESS: at sentence #90000, processed 1197796 words, keeping 20755 word types\n",
      "2019-10-22 20:44:35,056 : INFO : PROGRESS: at sentence #100000, processed 1324020 words, keeping 21381 word types\n",
      "2019-10-22 20:44:35,653 : INFO : PROGRESS: at sentence #110000, processed 1456096 words, keeping 21971 word types\n",
      "2019-10-22 20:44:35,821 : INFO : PROGRESS: at sentence #120000, processed 1597949 words, keeping 22527 word types\n",
      "2019-10-22 20:44:35,975 : INFO : collected 22901 word types from a corpus of 1728986 raw words and 128869 sentences\n",
      "2019-10-22 20:44:35,976 : INFO : Loading a fresh vocabulary\n",
      "2019-10-22 20:44:35,992 : INFO : effective_min_count=5 retains 11766 unique words (51% of original 22901, drops 11135)\n",
      "2019-10-22 20:44:35,993 : INFO : effective_min_count=5 leaves 1708087 word corpus (98% of original 1728986, drops 20899)\n",
      "2019-10-22 20:44:36,014 : INFO : deleting the raw counts dictionary of 22901 items\n",
      "2019-10-22 20:44:36,015 : INFO : sample=0.001 downsamples 50 most-common words\n",
      "2019-10-22 20:44:36,016 : INFO : downsampling leaves estimated 1299551 word corpus (76.1% of prior 1708087)\n",
      "2019-10-22 20:44:36,033 : INFO : estimated required memory for 11766 words and 300 dimensions: 34121400 bytes\n",
      "2019-10-22 20:44:36,034 : INFO : resetting layer weights\n",
      "2019-10-22 20:44:36,150 : INFO : training model with 4 workers on 11766 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=5\n",
      "2019-10-22 20:44:37,163 : INFO : EPOCH 1 - PROGRESS: at 10.95% examples, 141096 words/s, in_qsize 7, out_qsize 0\n",
      "2019-10-22 20:44:38,169 : INFO : EPOCH 1 - PROGRESS: at 22.71% examples, 145099 words/s, in_qsize 7, out_qsize 1\n",
      "2019-10-22 20:44:39,357 : INFO : EPOCH 1 - PROGRESS: at 43.43% examples, 170991 words/s, in_qsize 2, out_qsize 0\n",
      "2019-10-22 20:44:40,662 : INFO : EPOCH 1 - PROGRESS: at 66.14% examples, 189782 words/s, in_qsize 2, out_qsize 0\n",
      "2019-10-22 20:44:41,679 : INFO : EPOCH 1 - PROGRESS: at 86.10% examples, 199545 words/s, in_qsize 5, out_qsize 0\n",
      "2019-10-22 20:44:42,101 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-10-22 20:44:42,113 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-10-22 20:44:42,128 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-10-22 20:44:42,151 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-10-22 20:44:42,152 : INFO : EPOCH - 1 : training on 1728986 raw words (1298506 effective words) took 6.0s, 216444 effective words/s\n",
      "2019-10-22 20:44:43,181 : INFO : EPOCH 2 - PROGRESS: at 11.56% examples, 146603 words/s, in_qsize 7, out_qsize 0\n",
      "2019-10-22 20:44:44,223 : INFO : EPOCH 2 - PROGRESS: at 22.76% examples, 141658 words/s, in_qsize 7, out_qsize 0\n",
      "2019-10-22 20:44:45,410 : INFO : EPOCH 2 - PROGRESS: at 43.43% examples, 168528 words/s, in_qsize 0, out_qsize 1\n",
      "2019-10-22 20:44:46,635 : INFO : EPOCH 2 - PROGRESS: at 66.14% examples, 191284 words/s, in_qsize 0, out_qsize 1\n",
      "2019-10-22 20:44:47,699 : INFO : EPOCH 2 - PROGRESS: at 84.89% examples, 196496 words/s, in_qsize 1, out_qsize 0\n",
      "2019-10-22 20:44:48,256 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-10-22 20:44:48,287 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-10-22 20:44:48,289 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-10-22 20:44:48,295 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-10-22 20:44:48,296 : INFO : EPOCH - 2 : training on 1728986 raw words (1300025 effective words) took 6.1s, 211640 effective words/s\n",
      "2019-10-22 20:44:49,301 : INFO : EPOCH 3 - PROGRESS: at 9.79% examples, 127291 words/s, in_qsize 7, out_qsize 0\n",
      "2019-10-22 20:44:50,316 : INFO : EPOCH 3 - PROGRESS: at 23.34% examples, 148877 words/s, in_qsize 0, out_qsize 1\n",
      "2019-10-22 20:44:51,578 : INFO : EPOCH 3 - PROGRESS: at 43.43% examples, 167186 words/s, in_qsize 1, out_qsize 0\n",
      "2019-10-22 20:44:52,872 : INFO : EPOCH 3 - PROGRESS: at 66.14% examples, 187332 words/s, in_qsize 1, out_qsize 0\n",
      "2019-10-22 20:44:54,006 : INFO : EPOCH 3 - PROGRESS: at 84.89% examples, 190766 words/s, in_qsize 0, out_qsize 0\n",
      "2019-10-22 20:44:54,529 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-10-22 20:44:54,541 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-10-22 20:44:54,548 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-10-22 20:44:54,583 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-10-22 20:44:54,584 : INFO : EPOCH - 3 : training on 1728986 raw words (1299536 effective words) took 6.3s, 206726 effective words/s\n",
      "2019-10-22 20:44:55,624 : INFO : EPOCH 4 - PROGRESS: at 12.16% examples, 152103 words/s, in_qsize 0, out_qsize 1\n",
      "2019-10-22 20:44:56,634 : INFO : EPOCH 4 - PROGRESS: at 20.33% examples, 128258 words/s, in_qsize 2, out_qsize 1\n",
      "2019-10-22 20:44:58,054 : INFO : EPOCH 4 - PROGRESS: at 43.43% examples, 158212 words/s, in_qsize 1, out_qsize 0\n",
      "2019-10-22 20:44:59,442 : INFO : EPOCH 4 - PROGRESS: at 66.14% examples, 176424 words/s, in_qsize 2, out_qsize 0\n",
      "2019-10-22 20:45:00,479 : INFO : EPOCH 4 - PROGRESS: at 84.89% examples, 184768 words/s, in_qsize 1, out_qsize 0\n",
      "2019-10-22 20:45:01,009 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-10-22 20:45:01,014 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-10-22 20:45:01,032 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-10-22 20:45:01,047 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-10-22 20:45:01,048 : INFO : EPOCH - 4 : training on 1728986 raw words (1299479 effective words) took 6.5s, 201079 effective words/s\n",
      "2019-10-22 20:45:02,056 : INFO : EPOCH 5 - PROGRESS: at 10.41% examples, 134442 words/s, in_qsize 7, out_qsize 0\n",
      "2019-10-22 20:45:03,077 : INFO : EPOCH 5 - PROGRESS: at 22.76% examples, 144466 words/s, in_qsize 2, out_qsize 0\n",
      "2019-10-22 20:45:04,347 : INFO : EPOCH 5 - PROGRESS: at 43.43% examples, 166371 words/s, in_qsize 1, out_qsize 0\n",
      "2019-10-22 20:45:05,635 : INFO : EPOCH 5 - PROGRESS: at 66.14% examples, 186889 words/s, in_qsize 1, out_qsize 0\n",
      "2019-10-22 20:45:06,649 : INFO : EPOCH 5 - PROGRESS: at 84.89% examples, 194494 words/s, in_qsize 1, out_qsize 0\n",
      "2019-10-22 20:45:07,181 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-10-22 20:45:07,181 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-10-22 20:45:07,203 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-10-22 20:45:07,222 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-10-22 20:45:07,222 : INFO : EPOCH - 5 : training on 1728986 raw words (1299504 effective words) took 6.2s, 210528 effective words/s\n",
      "2019-10-22 20:45:07,223 : INFO : training on a 8644930 raw words (6497050 effective words) took 31.1s, 209097 effective words/s\n",
      "2019-10-22 20:45:07,224 : INFO : saving Word2Vec object under GOT-vectors.w2v, separately None\n",
      "2019-10-22 20:45:07,224 : INFO : not storing attribute vectors_norm\n",
      "2019-10-22 20:45:07,225 : INFO : not storing attribute cum_table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-10-22 20:45:07,420 : INFO : saved GOT-vectors.w2v\n",
      "2019-10-22 20:45:07,420 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('stormborn', 0.7817783355712891), ('unburnt', 0.7196938991546631), ('targaryen', 0.6913876533508301), ('kneel', 0.6648521423339844), ('rhaella', 0.6315736770629883)]\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    "        self.sentence_count = 0\n",
    "\n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            with open(os.path.join(self.dirname, fname)) as f_input:\n",
    "                corpus = f_input.read()\n",
    "            raw_sentences = sent_tokenize(corpus)\n",
    "            for sentence in raw_sentences:\n",
    "                if len(sentence) > 0:\n",
    "                    self.sentence_count += 1\n",
    "                    yield simple_preprocess(sentence) # tokenization, lowercasing ect... => retrun a list o\n",
    "\n",
    "\n",
    "sentences = MySentences('/data')\n",
    "\n",
    "model = Word2Vec(sg=1, # 1 for skip-gram; otherwise CBOW\n",
    "                 size=300, # num of features\n",
    "                 window=5,\n",
    "                 #min_count=3,\n",
    "                 workers=4)\n",
    "model.build_vocab(sentences)\n",
    "model.train(sentences=sentences, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "model.save('GOT-vectors.w2v')  # Save the model for later use\n",
    "\n",
    "print(model.wv.most_similar('daenerys', topn=5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6076681"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('jon', 'ygritte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70651907 0.7496346  0.66152644 ... 0.57311463 0.6294986  0.67315924]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv.distances('arryn'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('pays', 0.7023950219154358), ('tywin', 0.6980235576629639), ('kingslayer', 0.6655067205429077), ('debts', 0.6647920608520508), ('kevan', 0.651489794254303), ('jaime', 0.6432561874389648), ('stafford', 0.624941349029541)]\n",
      "[('pays', 0.7023950219154358), ('tywin', 0.6980235576629639), ('kingslayer', 0.6655067205429077), ('debts', 0.6647920608520508), ('kevan', 0.651489794254303), ('jaime', 0.6432561874389648), ('stafford', 0.624941349029541), ('cersei', 0.620202362537384), ('casterly', 0.6180166006088257), ('imp', 0.5923709869384766)]\n"
     ]
    }
   ],
   "source": [
    "# Top 5 ähnliche Begriffe\n",
    "print(model.wv.most_similar('lannister', topn = 7))\n",
    "\n",
    "# ODER\n",
    "print(model.wv.similar_by_word('lannister'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('eddard', 0.6230649948120117)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vektoren Addition / Subtraktion\n",
    "model.wv.most_similar(positive=['stark', 'winterfell'], negative=['dragons'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tluscre1/Applications/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'jaime'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match('winterfell riverrun jaime'.split())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
